{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: ML Tlachac\n",
    "#Paper: Depression Screening from Text Message Reply Latency\n",
    "#year: 2020\n",
    "#github.com/mltlachac/EMBC2020\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import collections\n",
    "import operator\n",
    "import argparse\n",
    "import random\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from statistics import mean \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from sklearn.decomposition import PCA, KernelPCA, NMF\n",
    "\n",
    "\n",
    "#randoms = []\n",
    "#for r in range(0, 100):\n",
    "#    randoms.append(random.randint(1,1000000000))\n",
    "#print(randoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = [361128390, 25678624, 286227372, 275413183, 835799483, 650031229, 381128932, 444496640, 170857706, 432939712, 369429758, 115346405, 35890687, 309457986, 109332894, 953403852, 252819303, 738792529, 241761773, 310165146, 896869903, 93132008, 144816658, 191300349, 602971087, 512359958, 399426044, 749247493, 414568457, 346244712, 736079420, 273441439, 142976366, 109103084, 925228403, 107949476, 738918921, 203448980, 922033929, 655505189, 48433776, 649673706, 321823331, 866307439, 217716963, 593539541, 803328973, 384847421, 31408796, 87997717, 592527218, 506246877, 590053539, 736896836, 252708346, 313920490, 623320593, 958675774, 364213774, 98505089, 59689233, 442316781, 326740111, 958938896, 759344068, 508584824, 645914056, 969919596, 969189324, 496406392, 660520068, 144918304, 653747834, 167562051, 900122744, 135334227, 966440225, 973306951, 495640847, 195133324, 496810208, 353187995, 814586150, 238549354, 419037670, 709650294, 549538988, 666493106, 606904926, 450619297, 675703044, 36759020, 102404976, 561079479, 670036183, 872070941, 909164647, 169045909, 730926233, 136792799]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision', 'recall', 'f1','accuracy', 'roc_auc']\n",
    "featureElist = [\"Chi\", \"PCA\", \"kPCA\"]\n",
    "splitlist = [10, 12, 15]\n",
    "\n",
    "namelist = [\"Texts\"]\n",
    "ndayslist = [14, 28, 42, 364]\n",
    "modelTypelist = [\"NB\", \"LR\", \"SVC1\", \"SVC2\", \"kNN3\", \"kNN5\", \"XG\", \"RF\"]\n",
    "\n",
    "for split in splitlist:\n",
    "    for featureE in featureElist:\n",
    "        for name in namelist:\n",
    "            for ndays in ndayslist:\n",
    "                for modelType in modelTypelist:\n",
    "\n",
    "                    df = pd.read_csv(\"latency\" + name + str(ndays) + \"cleaned.csv\")\n",
    "                    cnames = df.columns\n",
    "\n",
    "                    df0 = pd.DataFrame()\n",
    "                    for c in cnames:\n",
    "                        df0[c] = df[c].fillna(0)\n",
    "\n",
    "                    data = df0\n",
    "                    featureDF = []\n",
    "                    data[data.columns[-1]] = np.where(data[data.columns[-1]] >= split, 1, 0)\n",
    "                    featureSubset = data[data.columns[1:-1]]\n",
    "                    target = data[data.columns[-1]]\n",
    "                    min_max_scaler = preprocessing.MinMaxScaler()                   #NEED TO SCALE BEFORE FEATURE SELECTION!\n",
    "                    np_scaled = min_max_scaler.fit_transform(featureSubset)\n",
    "                    featureSubset = pd.DataFrame(np_scaled)\n",
    "\n",
    "                    if featureE == \"Chi\":\n",
    "                        nFeatureList = list(np.arange(1,11,1))\n",
    "\n",
    "                        for numberOfFeatures in nFeatureList:\n",
    "                            featureSubset2 = SelectKBest(chi2, k=numberOfFeatures).fit_transform(featureSubset, target)\n",
    "                            featureSubset2=pd.DataFrame(featureSubset2).assign(target = target)\n",
    "                            featureDF.append(featureSubset2)\n",
    "\n",
    "                    elif featureE == \"kPCA\":\n",
    "                        nFeatureList = list(np.arange(1,6,1))\n",
    "\n",
    "                        featureSubset2 = featureSubset#SelectKBest(chi2, k=17).fit_transform(featureSubset, target) #or feature subset\n",
    "                        for numberOfFeatures in nFeatureList:\n",
    "                            pca = KernelPCA(n_components=numberOfFeatures, kernel = \"rbf\")\n",
    "                            pca.fit(featureSubset2)\n",
    "                            X_pca = pca.transform(featureSubset2)\n",
    "                            pcaDF = pd.DataFrame(X_pca)#pca.components_.transpose())\n",
    "                            pcaDF = pcaDF.assign(target = target)\n",
    "                            \n",
    "\n",
    "                            featureDF.append(pcaDF)\n",
    "\n",
    "                    elif featureE == \"PCA\":\n",
    "                        nFeatureList = list(np.arange(1,6,1))\n",
    "\n",
    "                        featureSubset2 = featureSubset#SelectKBest(chi2, k=17).fit_transform(featureSubset, target) #or feature subset\n",
    "                        for numberOfFeatures in nFeatureList:\n",
    "                            pca = PCA(n_components=numberOfFeatures)\n",
    "                            pca.fit(featureSubset2)\n",
    "                            X_pca = pca.transform(featureSubset2)\n",
    "                            pcaDF = pd.DataFrame(X_pca)#pca.components_.transpose())\n",
    "                            pcaDF = pcaDF.assign(target = target)\n",
    "                            \n",
    "\n",
    "                            featureDF.append(pcaDF)\n",
    "\n",
    "\n",
    "                    alist = []\n",
    "                    flist = []\n",
    "                    mlist = []\n",
    "                    plist = []\n",
    "                    featureList = []\n",
    "                    precisionList = []\n",
    "                    recallList = []\n",
    "                    f1List = []\n",
    "                    accuracyList = []\n",
    "                    aucList = []\n",
    "                    truePosList = []\n",
    "                    trueNegList = []\n",
    "                    falsePosList = []\n",
    "                    falseNegList = []\n",
    "                    predictions = []\n",
    "                    randomseed = []\n",
    "                    shape = []\n",
    "\n",
    "                    for number in randoms:\n",
    "                        r = number\n",
    "                        print(r)\n",
    "                        random.seed(r)\n",
    "\n",
    "                        for f in range(0, len(featureDF)):\n",
    "\n",
    "                            featureSubset = featureDF[f] #pcaDF or featureDF[f]\n",
    "\n",
    "                            targetClassCount = collections.Counter(featureSubset[featureSubset.columns[-1]])\n",
    "                            majorityKey = max(targetClassCount, key=targetClassCount.get)\n",
    "                            majorityCount = targetClassCount[majorityKey]\n",
    "                            minorityKey = min(targetClassCount,  key=targetClassCount.get)\n",
    "                            minorityCount = targetClassCount[minorityKey]\n",
    "\n",
    "                            featureSubset_majority = featureSubset[featureSubset[featureSubset.columns[len(featureSubset.columns)-1]] == majorityKey]\n",
    "                            featureSubset_minority = featureSubset[featureSubset[featureSubset.columns[len(featureSubset.columns)-1]] == minorityKey]\n",
    "                            featureSubset_majority_downsampled = resample(featureSubset_majority, replace=False, n_samples=minorityCount, random_state=r) # reproducible results\n",
    "                            featureSubset_downsampled = pd.concat([featureSubset_majority_downsampled, featureSubset_minority])\n",
    "                            featureSubset_downsampled = featureSubset_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "                            featureSubset = featureSubset_downsampled\n",
    "\n",
    "                            target = featureSubset[featureSubset.columns[-1]]  \n",
    "                            featureSubset = featureSubset[featureSubset.columns[:-1]] #Skip PHQ-9 Responses \n",
    "\n",
    "                        #for i in range(0, len(modelList)):\n",
    "                            featureList.append(nFeatureList[f])  ###########\n",
    "                            flist.append(name)\n",
    "                            mlist.append(modelType)\n",
    "                            if modelType == \"SVC1\":\n",
    "                                clf = svm.SVC(kernel='rbf', random_state=r)\n",
    "                            elif modelType == \"SVC2\":\n",
    "                                clf = svm.SVC(kernel='linear', random_state=r)\n",
    "                            elif modelType == \"RF\":\n",
    "                                clf = RandomForestClassifier(criterion=\"gini\", max_depth=3, random_state=r)\n",
    "                            elif modelType == \"kNN3\":\n",
    "                                clf = KNeighborsClassifier(n_neighbors=3)\n",
    "                            elif modelType == \"kNN5\":\n",
    "                                clf = KNeighborsClassifier(n_neighbors=5)\n",
    "                            elif modelType == \"XG\":\n",
    "                                clf = xgb.XGBClassifier(max_depth=3, random_state=r)\n",
    "                            elif modelType == \"LR\":\n",
    "                                clf = LogisticRegression(random_state=r)\n",
    "                            elif modelType == \"NB\":\n",
    "                                clf = GaussianNB()\n",
    "\n",
    "                            scores = cross_validate(clf, featureSubset, target, scoring=scoring,cv=5, return_train_score=False)\n",
    "                            y_pred = cross_val_predict(clf, featureSubset, target, cv=5)\n",
    "\n",
    "                            conf_mat = confusion_matrix(target, y_pred)\n",
    "                            TN = conf_mat[0][0]\n",
    "                            TP = conf_mat[1][1]\n",
    "                            FP = conf_mat[0][1]\n",
    "                            FN = conf_mat[1][0]\n",
    "                            precision = mean(scores['test_precision'])\n",
    "                            sensitivity = mean(scores['test_recall'])\n",
    "                            f1 = mean(scores['test_f1'])\n",
    "                            accuracy = mean(scores['test_accuracy'])\n",
    "                            auc = mean(scores['test_roc_auc'])\n",
    "\n",
    "                            precisionList.append(precision)\n",
    "                            recallList.append(sensitivity)\n",
    "                            f1List.append(f1)\n",
    "                            accuracyList.append(accuracy)\n",
    "                            aucList.append(auc)\n",
    "                            truePosList.append(TP)\n",
    "                            trueNegList.append(TN)\n",
    "                            falsePosList.append(FP)\n",
    "                            falseNegList.append(FN)\n",
    "                            predictions.append(y_pred)\n",
    "                            randomseed.append(r)\n",
    "                            shape.append(df0.shape)\n",
    "\n",
    "                        resultsDF = pd.DataFrame()\n",
    "                        resultsDF[\"texts\"] = flist\n",
    "                        resultsDF[\"model\"] = mlist\n",
    "                        resultsDF[\"nFeatures\"] = featureList\n",
    "                        resultsDF[\"precision\"] = precisionList\n",
    "                        resultsDF[\"recall\"] = recallList\n",
    "                        resultsDF[\"F1\"] = f1List\n",
    "                        resultsDF[\"Accuracy\"] = accuracyList\n",
    "                        resultsDF[\"AUC\"] = aucList\n",
    "                        resultsDF[\"truePos\"] = truePosList\n",
    "                        resultsDF[\"trueNeg\"] = trueNegList\n",
    "                        resultsDF[\"falsePos\"] = falsePosList\n",
    "                        resultsDF[\"falseNeg\"] = falseNegList\n",
    "                        resultsDF[\"predictions\"] = predictions\n",
    "                        resultsDF[\"randomN\"] = randomseed\n",
    "                        resultsDF[\"shape\"] = shape\n",
    "\n",
    "                        resultsDF.to_csv(\"latencyResults/latencyResults\" + name + str(split) + modelType + str(ndays) + \"days\" + featureE + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
